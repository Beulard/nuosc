\label{ch:methods}
In this chapter, we will discuss the statistics of experimental sensitivity,
our implementation of neutrino oscillations and how it fits into models of
long-baseline neutrino experiments.
We will concisely present examples of oscillation probability plots
produced by our oscillation model, followed by a detailed section on the
modelling of the DUNE experiment. At the end of the chapter, we will show our
predictions for the sensitivity of both DUNE and Hyper-K to the mass hierarchy
and to CP violation. 

\section{Statistical analysis}\label{sec:statistics}
In this section, we will introduce qualitatively and quantitatively the definition of
\emph{sensitivity} in the context of neutrino oscillation experiments. With a
short derivation, we will show that in the case of the mass hierarchy question,
the $\Delta \chi^2$ statistic is Gaussian-distributed around its mean,
$\overline{\Delta \chi^2}$, which is the quantity we will determine from our
model and use as a measure of sensitivity.

\subsection{Experimental sensitivity}
Neutrino experiments are characterised by the extremely small scattering cross
section of weak processes. Neutrinos are almost massless, have no charge, and
being leptons, they are not affected by strong interactions. These unique
properties make their detection particularly difficult and the associated
experiments particularly costly and time-inefficient. The best way for
experimentalists to compensate for a small cross section is to increase the scale
of their detector. 

The Sudbury Neutrino Observatory (SNO) experiment, which confirmed
the existence of matter effects on neutrino oscillations in 2001, consisted of 1000
tons of heavy water enclosed in a sphere of diameter 12 meters\cite{thomson}.
The DUNE experiment, expected to start collecting data in 2024, will use 4850L
of liquid argon for a total fiducial mass\footnote{The outermost parts of the
detector are more sensitive to background events. To account for this, all
events outside the more reliable central region are discarded. The part of the
total detector mass that remains is called fiducial mass.} of 40~kilotons\cite{cdr}.
For projects of this scale, it is crucial to try to maximize the time and cost
efficiency of the experiment by optimizing its design. It is thus conventional as part of
the design process to evaluate the experiment's sensitivity to the relevant
physical parameters. This evaluation can be done concurrently with the
evolution and refinement of the project. It can then be used to legitimize
the project to the scientific community and attract the support of funding
agencies.

In general, it may be ambiguous which design choices will lead to a better
sensitivity.  As a consequence, experimentalists have devised statistical
methods to allow the quantification of sensitivity in order to compare
different designs or even different experiments, and to be able to do so in a
mathematically rigorous way that is accepted by the most scientists.
When applied, these methods also enable us to compare potential experiments that
could have different characteristics --- baseline, detector technology,
neutrino source --- and to understand the complementarities that could result
from combining their results.



\subsection{Sensitivity to the mass hierarchy}
In a general experiment where a set of data $y_i$ is collected, one can
evaluate the goodness of fit between the data and a model using the
$\chi^2$ statistic:
\begin{equation}
	\chi^2(\theta) = \sum_i \frac{(y_i -
	n_i(\theta))^2}{\sigma^2_i},\label{eq:chisq}
\end{equation}
where $n_i(\theta)$ are the values predicted by the model using a set of parameters
$\theta$, and $\sigma_i$ is the uncertainty associated with the measurement $y_i$.
This statistic can be minimized in parameter-space to yield the best-fit
$\theta$, i.e. the set of parameters that seems to most accurately describe nature:
\begin{equation}\chi^2_\text{min} = \min_\theta \sum_i \frac{(y_i -
n_i(\theta))^2}{\sigma^2_i}.\label{eq:c2_min}\end{equation}
If $n$ measurements were made and $\theta$ contains $p$ parameters, this
minimum $\chi^2$ will be distributed according to a $\chi^2$ distribution with
$n-p$ degrees of freedom, allowing us to determine a confidence level for
rejecting the null hypothesis.

When trying to determine the mass hierarchy, we need a test statistic that can
distinguish between the two hypotheses. We define
\begin{equation}\Delta \chi^2 = \min_{\theta \in \text{IH}} \chi^2(\theta) - \min_{\theta \in
\text{NH}} \chi^2(\theta),\label{eq:dc2}\end{equation}
where $\theta$ are parameters constrained to a particular mass hierarchy in the
minimization. The sign of this statistic indicates which hierarchy seems to
best fit our data. Its distribution, which in general is not a $\chi^2$
distribution, gives us the confidence level at which we can reject one of the
hierarchies.

In the context of future experiments, we cannot evaluate $\chi^2$ since no
measurements have been made. A standard procedure\cite{blennow} to evaluate
sensitivity is to replace the
measurements $y_i$ by the best prediction we can make with our model. Assuming
that the true hierarchy is NH, and that the true parameters are $\theta_0$, our
``most probable data set\footnote{Also referred to as Asimov data set.}'' is
$n^\text{N}_i(\theta_0)$, where the superscript denotes the assumed true
hierarchy. Substituting this for $y_i$ in eqs.~\ref{eq:c2_min} and~\ref{eq:dc2}:
\begin{align*}
	\overline{\Delta\chi^2} (\theta_0) &= \min_{\theta \in \text{IH}}
\sum_i \frac{(n^\text{N}_i(\theta_0) - n_i (\theta))^2}{\sigma^2_i}
- \min_{\theta \in \text{NH}}
\sum_i \frac{(n^\text{N}_i(\theta_0) - n_i (\theta))^2}{\sigma^2_i},
\end{align*}
where the bar over $\Delta\chi^2$ indicates that it is associated with the most
probable data set. Clearly, the second term vanishes since it is minimized
over parameters that are compatible with the most probable data. We are left
with
\begin{equation}
	\overline{\Delta\chi^2} (\theta_0) = \min_{\theta \in \text{IH}}
	\sum_i \frac{(n^\text{N}_i(\theta_0) - n_i
	(\theta))^2}{\sigma^2_i}.\label{eq:sens_mh}
\end{equation}
Note that this is not a proper test statistic, since it does not depend on any
measured data, but only on predictions. Heuristically, it is a measure of how
incompatible the two hierarchies are in terms of the number of events we expect
to measure in the experiment. Hence it makes sense to define
eq.~\ref{eq:sens_mh} as the sensitivity to the mass hierarchy\footnote{If
instead we assume the true hierarchy to be IH, our most probable data set is
$n^\text{I}_i(\theta_0)$ and we are left with only the second term:
\begin{equation*}
	\overline{\Delta\chi^2} (\theta_0) = -\min_{\theta \in \text{NH}}
	\sum_i \frac{(n^\text{I}_i(\theta_0) - n_i
	(\theta))^2}{\sigma^2_i}.
\end{equation*}}.
However, we can be more quantitative in our treatment by determining the
distribution of $\Delta\chi^2$ from eq.~\ref{eq:dc2} and its relation to
eq.~\ref{eq:sens_mh}. 
This will allow us to give a more rigorous statistical interpretation to the
sensitivity.




\subsubsection{Distribution of $\Delta \chi^2$ for the mass hierarchy}
The mass hierarchy can only turn out to be normal (NH), or inverted (IH). As
such, it is considered as a discrete, non-nested hypothesis --- in contrast with a continuous
variable such as $\delta_{CP}$ or $\theta_{23}$. For this derivation, we consider the simple case
where there are no nuisance parameters, as discussed in~\cite{ciuffoli, qian}.
Hence the set of parameters $\theta$ of eq.~\ref{eq:chisq} is reduced to the
choice of mass hierarchy, and the minimization of equation~\ref{eq:dc2} is trivial.

We denote by $y_i$ the event count recorded by a neutrino experiment per energy
bin, where $i = 1, 2, ..., N$ is the index of the energy bin.
Given that enough data has been collected,
the event counts $y_i$ will be distributed around their true value
according to a Gaussian with variance $\sigma^2_i=y_i$ (Poisson variable). 
Our model will yield predicted event counts that will depend on
the true mass hierarchy.  We denote by $n^\text{N}_i$ the predicted count under normal
hierarchy and by $n^\text{I}_i$ the predicted count under inverted hierarchy.
Let us assume that the true hierarchy --- the one picked by nature --- is normally
ordered. Then, assuming our model accurately describes nature,  we can write
our experimental event counts as $y_i = n^\text{N}_i + \sigma_i g_i$, where
$g_i$ is a random variable from a Gaussian distribution centered at zero and
with variance 1.
The $\Delta \chi^2$ statistic of equation~\ref{eq:dc2} can then be written as
\begin{align}
	\Delta \chi^2 &= \chi_\text{I}^2 - \chi_\text{N}^2\nonumber\\
	&= \sum_i \frac{(y_i - n^\text{I}_i)^2}{\sigma_i^2} - \sum_i \frac{(y_i -
	n^\text{N}_i)^2}{\sigma_i^2}\nonumber\\
	&= \sum_i \frac{(n^\text{N}_i + \sigma_i g_i - n^\text{I}_i)^2 - (n^\text{N}_i + \sigma_i g_i -
	n^\text{N}_i)^2}{\sigma_i^2}\nonumber\\
	&= \sum_i \frac{(n^\text{N}_i - n^\text{I}_i)^2}{n^\text{N}_i} + \sum_i
	\frac{2(n^\text{N}_i -
	n^\text{I}_i)}{n^\text{N}_i} g_i,\label{eq:dc2_mh}
\end{align}
where in the last step we have used that $\sigma_i = \sqrt{y_i} \approx \sqrt{n^\text{N}_i}$
when our event count is large.
In this form, we can see that $\Delta \chi^2$ is a Gaussian-distributed
variable where the mean is the first term of eq.~\ref{eq:dc2_mh}:
\begin{equation}
	\overline{\Delta\chi^2} \equiv \sum_i \frac{(n^\text{N}_i -
n^\text{I}_i)^2}{n^\text{N}_i},\label{eq:mean_dc2_mh}\end{equation}
and the standard deviation is
$$\sigma_{\Delta\chi^2} \equiv \sqrt{\sum_i \frac{4(n^\text{N}_i -
n^\text{I}_i)^2}{n^\text{N}_i}}\\
= 2\sqrt{\overline{\Delta\chi^2}}.$$
Hence, the sensitivity we evaluate from our model is actually the mean value of
the $\Delta\chi^2$ statistic, whose purpose is to distinguish between the two
hierarchies. Quantitatively, as shown by Blennow et al.\cite{blennow}, the square root of
$\overline{\Delta\chi^2}$ in fact corresponds to the confidence level at which the
experiment will be able to reject the inverted hierarchy with a 50\% chance of
type~II error\footnote{Type II error: accepting a hypothesis although it is
false.}. 

We recognize in eq.~\ref{eq:mean_dc2_mh} the sensitivity of
eq.~\ref{eq:sens_mh} without the parameters $\theta$.  However, for neutrino
oscillations, we cannot treat all the other parameters as constant since
$\delta_{CP}$ and $\theta_{23}$ are not yet fully determined. In general, it
will be more informative to use eq.~\ref{eq:sens_mh} as a measure of
sensitivity rather than eq.~\ref{eq:mean_dc2_mh}, although we lose the nice
properties that we have outlined above, namely the $\Delta\chi^2$ statistic
will no longer be exactly Gaussian-distributed. In this case, the distribution
of $\Delta\chi^2$ must in general be determined explicitely through Monte Carlo
simulations, which is beyond the scope of this report. It is however discussed
and performed in~\cite{blennow} for the NOvA and DUNE experiments among others.
Their results indicate that the $\Delta\chi^2$ statistic we define in
eq.~\ref{eq:dc2} is approximately Gaussian-distributed, at least in the context
of DUNE. Thus, we may also apply the interpretation given in the previous
paragraph to the more general sensitivity of eq.~\ref{eq:sens_mh}.


For simplicity, we will regard $\theta_{23}$ as a fixed parameter --- not to
be minimized --- since its precise value
does not affect the oscillation probability we calculate to model
DUNE\footnote{More accurately, the octant of $\theta_{23}$ can only be measured
if the LBNF is run in both neutrino and anti-neutrino mode\cite{raut}. In our model, we
are only considering the neutrino mode, hence $\theta_{23}$ is effectively a
fixed parameter.}. Hence, we can write the sensitivity to the mass
hierarchy as
\begin{equation}
	\overline{\Delta\chi^2}(\delta_0) = \min_\delta \sum_i \frac{(n^\text{N}_i
	(\delta_0) - n^\text{I}_i
	(\delta))}{n^\text{N}_i(\delta_0)},\label{eq:mean_dc2_mh_d}
\end{equation}
where now we are only minimizing over $\delta_{CP} \in [-\pi,
\pi]$, and $\delta_0$ is our assumed true $\delta_{CP}$.
We will plot equation~\ref{eq:mean_dc2_mh_d} as a function of
$\delta_0$ for the DUNE experiment later in this chapter, after discussing the
DUNE model.



\subsection{Sensitivity to CP violation}\label{sec:sens_cpv}
In addition to the sensitivity to the mass hierarchy, we can estimate the
sensitivity to CP violation as a function of $\delta_{CP}$ using a similar
statistic as eq.~\ref{eq:mean_dc2_mh_d}. The sensitivity to CP violation
is the ability of the experiment to discriminate between values of
$\delta_{CP}$ that violate CP and values that do not. The only values that
do not violate CP are $\delta_{CP}=0$ and $\delta_{CP}=\pi$. Hence we define
\begin{equation}
	\overline{\Delta\chi^2}_{CPV}(\delta_0) \equiv \min\bigg(\sum_i
	\frac{(n_i(\delta_0) - n_i(0))^2}{n_i(\delta_0)},~~\sum_i
	\frac{(n_i(\delta_0) - n_i(\pi))^2}{n_i(\delta_0)}\bigg),\label{eq:dc2_cpv}
\end{equation}
where $\delta_0$ is our assumed true value of $\delta_{CP}$, and the assumed mass
hierarchy is not specified for generality. In equation~\ref{eq:dc2_cpv}, we are
evaluating a goodness of fit between a model where CP is violated and a model
where CP is conserved (except for $\delta_0=0,~\pi$; then
$\overline{\Delta\chi^2}_{CPV}=0$). 
This tells us, for every possible true value of $\delta_{CP}=\delta_0$, how
badly the most probable data fits CP-conserving models; hence how easily CP
conservation can be ruled out. We will also show plots of CP violation sensitivity
at the end of this chapter. 

In the case of the sensitivity to CP violation, the $\overline{\Delta\chi^2}$
we have defined in~\ref{eq:dc2_cpv} does not, in general, correspond to the mean
value of the $\Delta\chi^2$ statistic. In order to make such a claim, one would
have to determine the distribution of $\Delta\chi^2$ through Monte Carlo
techniques. Surprisingly, to the extent of our research, and unlike the case of
the mass hierarchy sensitivity, this has not been done in the literature.  It
is thus impossible to assign to this $\overline{\Delta\chi^2}$ a rigorous
statistical interpretation, which is problematic. In retrospect, a solution
would have been to perform the simulations ourselves and present the results
here, although it would have required a significant time investment to
refurbish the code for such a purpose.


\section{Neutrino oscillations model}
By implementing the concepts introduced in the previous chapter, we are able to
model the oscillation of neutrinos through a vacuum or through matter.

The first step of our work was to implement in code the phenomenological
oscillation formulae of chapter~\ref{ch:osc}. The simplest test case
is equation~\ref{eq:twonu}, the oscillation between two neutrino flavours.
Figure~\ref{fig:twonu_plots} shows the oscillation
probability of a neutrino initially produced as a $\nu_\mu$. 
\begin{figure}
	\centering
	\includegraphics[width=0.6\textwidth]{twonu_test.pdf}
	\captionsetup{width=0.9\textwidth}
	\caption{Oscillation probability vs. $L/E$ for two neutrino flavours. The
	amplitude is governed by $\theta$ while the frequency is proportional to
	$\Delta m^2$. The mixing between flavours is almost maximal, i.e. the
	appearance of $\nu_\tau$ is almost 100\% at the half period.}
	\label{fig:twonu_plots}
\end{figure}
For this plot, we picked the parameters $\Delta m^2$ and $\theta$ (shown in
figure) from global fits of past experiments, reported by the Particle Data
Group (PDG)\cite{pdg}.

The next step is to implement three-neutrino oscillations. This involves
implementing the complex PMNS matrix of eq.~\ref{eq:PMNS} and the more general
probability function of eq.~\ref{eq:nuprob}. 
\begin{figure}
	\centering
	\makebox[1\textwidth][c]{
		\centering
	\begin{subfigure}[b]{0.6\textwidth}
		\centering
		\includegraphics[width=\textwidth]{threenu_0.pdf}
	\end{subfigure}
	\begin{subfigure}[b]{0.6\textwidth}
		\centering
		\includegraphics[width=\textwidth]{threenu_pihalf.pdf}
	\end{subfigure}}
\caption{Oscillation probability for a neutrino produced as a $\nu_e$, allowed to
	oscillate to $\nu_\tau$ and $\nu_\mu$. The mass hierarchy is NH for both
	plots. We illustrate the difference made by
	the CP-violating phase by showing a plot where CP is conserved
	($\delta_{CP}=0$) and a plot where CP is maximally violated ($\delta_{CP} =
	\pi/2$).}
\label{fig:threenu_plots}
\end{figure}
Figure~\ref{fig:threenu_plots} shows the oscillation probability for a neutrino
starting as a $\nu_e$ as a function of $L/E$. All parameters except
$\delta_{CP}$ are best-fit values listed by the PDG under the
assumption that the true mass hierarchy is normally ordered.
Table~\ref{tab:threenu_params} shows these values.


\begin{wraptable}{r}[2cm]{0.36\textwidth}
	\captionsetup{justification=centering}
	\centering
\begin{tabular}{ | c | c | }
	\hline
	Parameter & Value\\\hline
	$\Delta m^2_{21}$ & \SI{7.37e-5}{\eV^{-2}}\\
	$|\Delta m^2_{31}|$ & \SI{2.56e-3}{\eV^{-2}}\\
	$\theta_{12}$		  & 0.576\\
	$\theta_{23}$			& 0.710\\
	$\theta_{13}$ 		& 0.147\\\hline
\end{tabular}
	\caption{Parameter values used in our neutrino oscillations model.}
	\label{tab:threenu_params}
\end{wraptable}

The difference between the two plots in figure~\ref{fig:threenu_plots} clearly
shows that given all other parameters, it is possible to determine the true
value of $\delta_{CP}$ by measuring neutrino appearance rates. Unfortunately,
the problem is not that easily solved. In neutrino experiments, reconstructing
the energy of neutrinos in the detector is difficult and prone to random and
systematic errors. Additionally, while some parameters are known with good
precision ($\theta_{12}, \theta_{13}, \Delta m^2_{21}$), the others remain
elusive and challenging to measure independently of each other.
Corrections must also be applied when the oscillations take place
through matter. It is necessary to choose an appropriate and reliable model of the
of the medium through which the neutrinos propagate, since the potential $V_e$ of
equation~\ref{eq:matter_potential} is proportional to the electron density in
the medium.


\section{Modelling an accelerator-based long baseline experiment}

\subsection{The DUNE experiment}
The Deep Underground Neutrino Experiment (DUNE) is a future long-baseline
experiment designed to --- among other goals --- determine the CP violating phase
$\delta_{CP}$, the neutrino mass hierarchy (the sign of $\Delta m^2_{31}$) and
the octant of $\theta_{23}$ (whether it is greater or less than 
$\pi/4$)\cite{cdr}. 
It will make use of Fermilab's Long-Baseline Neutrino Facility (LBNF) in Batavia,
Illinois for the production of a high-intensity neutrino beam aimed at the
Sanford Underground Research Facility, \SI{1300}{\km} away, where the DUNE
detectors will be built.
Four liquid argon time-projection chambers (LArTPC) of fiducial mass
\SI{10}{\kt} each will serve as detectors, with the ability to reconstruct the
trajectories and kinematic quantities of interacting neutrinos.
DUNE will primarily observe the oscillations from $\nu_\mu$ to $\nu_e$ in the
LBNF beam. This appearance channel alone is expected to provide enough data to
reach the objectives mentioned above, as we will show later.
The neutrino beam will travel through the Earth's crust for \SI{1300}{\km},
hence matter effects must be taken into account.

The DUNE experiment is thus a perfect candidate to try our simple model and see if
we can reproduce results from the literature, namely predictions on the
potential outcomes of the experiment.

\subsection{Event rate at the detector}\label{sec:event}
In order to predict an event rate $N$ in a general detector, we usually need three
elements: the luminosity of the beam $L$, the interaction cross section $\sigma$, and the
efficiency of the detector $\eps$:
\begin{equation}N = \eps L \sigma,\label{eq:rate}\end{equation}
where $L$ has units \si{\m^{-2} \s^{-1}}, $\sigma$ has units \si{\m^2} and
$\eps$ is unitless.
We will use a modified version of this approach to predict event rates inside
DUNE's liquid argon time-projection chamber (LArTPC), as a function of
energy. While our model
accurately describes the flavour oscillations of neutrinos, we are unable to
estimate the neutrino flux coming out of the LBNF accelerator, or the
efficiency of the LArTPC. For these two aspects we will rely on results
presented by the DUNE collaboration in their conceptual design report (CDR).

To produce the neutrinos, the LBNF accelerates protons which collide with a
graphite target to produce secondary mesons ($\pi^+, \pi^-$). These particles are focused
along a decay pipe where they decay into muons and their associated muon
neutrinos\cite{papadimitriou}. Hence by modelling the proton/target collision and the
decay of secondary mesons, one can estimate the flux of neutrinos produced by
the accelerator. The volume 3 of the CDR\cite{cdr_vol3} provides the predicted
flux of $\nu_\mu$ and $\nu_e$ at the detector in the absence of oscillations.
To produce these results, they use the \textsc{Geant4}\cite{Geant4} software to simulate
the beamline from the reference design of the LBNF accelerator.
Figure~\ref{fig:nuflux} shows a reproduction of the resulting plot from the DUNE CDR.
\begin{figure}
	\centering
	\includegraphics[width=0.5\textwidth]{dune_flux.pdf}
	\caption{Predicted neutrino flux at the DUNE detector in the absence of
	oscillations, when focusing positively charged pions through the decay pipe. 
	``POT'' stands for protons on target.
	Reproduction of figure 6-2 from the DUNE CDR Vol.
	3\cite{cdr_vol3}.}
	\label{fig:nuflux}
\end{figure}

It is fairly simple to convert this ``un-oscillated'' spectrum into an
``oscillated'' one. Typically in accelerator-based experiments, the observed oscillation channel
is the $\nu_\mu \rightarrow \nu_e$ appearance. Hence for each bin in the
spectrum of figure~\ref{fig:nuflux}, we multiply the un-oscillated
muon-neutrino flux
$\Phi^{(\mu)}_0$ (blue line) by the $\nu_\mu \rightarrow \nu_e$ oscillation
probability:
\begin{equation}
	\Phi^{(e)}_\text{osc} (E_i) = P_{\nu_\mu \rightarrow \nu_e} (E_i) \times
\Phi^{(\mu)}_0 (E_i),\label{eq:flux}\end{equation}
where $\Phi^{(e)}_\text{osc}$ is the flux of electron-neutrinos resulting from
$\nu_\mu$ oscillations, and $i$ indexes energy bins.
We show this $P_{\nu_\mu \rightarrow \nu_e}$ function for different values of
$\delta_{CP}$ and the two possible mass hierarchies on
figure~\ref{fig:dune_prob}. We also illustrate the influence of matter effects
on the appearance probability by showing oscillations in vacuum and in the
Earth's mantle.
\begin{figure}
	\centering
	\makebox[\textwidth][c]{
		\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{dune_prob_nh_vac.pdf}
			\caption{Vacuum, NH}\label{fig:vacNH}
		\end{subfigure}
		\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{dune_prob_ih_vac.pdf}
			\caption{Vacuum, IH}\label{fig:vacIH}
		\end{subfigure}}
	\makebox[\textwidth][c]{
	\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{dune_prob_nh.pdf}
		\caption{Matter, NH}\label{fig:matNH}
		\end{subfigure}
		\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{dune_prob_ih.pdf}
			\caption{Matter, IH}\label{fig:matIH}
		\end{subfigure}}
	\caption{Oscillation probability $\nu_\mu \rightarrow \nu_e$ as a function of
	neutrino energy for neutrinos travelling over a baseline $L=\SI{1300}{\km}$.
	Plots on the left have a normally ordered mass hierarchy, and plots on the
	right an inverted mass hierarchy. On top, neutrinos are oscillated in empty
	space, and on the bottom they are oscillated through matter of constant
	electron density $N_e=2.2 N_A~\si{\cm^{-3}}$, where $N_A$ is Avogadro's
	constant\cite{freund}. All vacuum oscillation parameters are
	listed in table~\ref{tab:threenu_params}.}
\label{fig:dune_prob}
\end{figure}

In general, the first (rightmost) peak\footnote{It is the ``first peak''
because the probability falls to zero at higher energies. Note that the curves
in figure~\ref{fig:threenu_plots} had $L/E$ on the x-axis, while those in
figure~\ref{fig:dune_prob} are plotted against $E$. Hence the region covered by
the latter corresponds to the leftmost part of the former.} in the oscillation
probability will provide the best signal, since it is wider than all other
peaks on the energy axis, and thus easier to resolve.
The first oscillation peak for the DUNE baseline $L=\SI{1300}{\km}$ occurs between 1 and
\SI{10}{\GeV}, and thus it is the
energy range of choice for the DUNE experiment\cite{cdr}. 

It is interesting to observe that matter effects enhance the amplitude of
oscillations for the NH, and reduce it for the IH. The mass hierarchy only
influences the sign of one of the mass-squared differences, thus in a vacuum it
only affects the frequency of oscillations, as is shown on
figures~\ref{fig:vacNH} and~\ref{fig:vacIH}: the peak amplitudes are left
unchanged under a change of hierarchy. In vacuum, we can only change the
amplitude by changing the mixing angles. We see on figures~\ref{fig:matNH}
and~\ref{fig:matIH} that matter effects mix the parameters --- as is manifest
already for two neutrinos in equation~\ref{eq:deltam2m} --- in such a way that the
mass hierarchy can impact the amplitude as well. This feature is crucial to
DUNE's sensitivity to the mass hierarchy, as it will make discriminating
between the two hypotheses much easier than if the neutrinos were propagating
in empty space.

Now that we have the neutrino flux in the detector, i.e.~the luminosity
variable of equation~\ref{eq:rate}, we would normally need a model of the weak
interactions with the liquid argon ($\sigma$) and of the detector efficiency
($\eps$).
However another option is to normalize the flux to the integrated event rate,
i.e.~the total number of events expected to be observed during a given exposure
time. If we denote by $N_\text{int}$ this integrated event rate, then the
predicted event rate per unit energy is
\begin{equation}
	\frac{\md N}{\md E} = \frac{N_\text{int}}{\int \Phi^{(e)}_\text{osc} (E)~\md E}
	\times \Phi^{(e)}_\text{osc} (E).
\end{equation}
In other words, we first normalize the flux spectrum $\Phi^{(e)}_\text{osc}$ to
1 by dividing it by its integral, and then normalize to the integrated event
rate by multiplying by $N_\text{int}$.
Since our flux is a function of discrete energy bins, we can rewrite this as
\begin{align}
	\frac{N_i}{\Delta E} &= \frac{N_\text{int}}{\sum\limits_j \Phi^{(e)}_\text{osc} (E_j)
	\Delta E} \times \Phi^{(e)}_\text{osc} (E_i)\nonumber\\\implies
	N_i &= \frac{N_\text{int}}{\sum\limits_j \Phi^{(e)}_\text{osc} (E_j)} \times
	\Phi^{(e)}_\text{osc} (E_i),\label{eq:event_rate_0}
\end{align}
where $N_i$ is now the event rate per energy bin.
Thus, from the integrated event rate, we are able to retrieve the event rate as
a function of energy. We can then use this data to obtain the experiment's
sensitivity to the mass hierarchy and $\delta_{CP}$.

The CDR uses the \textsc{Genie}\cite{GENIE} neutrino event generator and a
parametrized detector response, to process the neutrino flux and
obtain an event rate through Monte Carlo simulations. This complex modelling
allows them to predict that the total number of CC events from $\nu_e$
appearance between 0.5 and \SI{8}{\GeV} during an exposure of 150
kt$\cdot$MW$\cdot$year will be $N^\text{N}_\text{int}=861$ if the true
hierarchy is normal, and $N^\text{I}_\text{int}=495$ if it is inverted.
Although both results assume that $\delta_{CP}=0$, we will be able to calculate
the event rates for all values of $\delta_{CP}$ using our model.

As can be seen on any of the graphs of figure~\ref{fig:dune_prob}, the area under the first
appearance peak is different for different values of $\delta_{CP}$. This
indicates that the integrated event rate depends on $\delta_{CP}$.
The integrated event rate for any $\delta_{CP}$ is given by
\begin{align}
	N_\text{int} (\delta) &= \frac{\int P (
	\delta)~\md E}{\int P (
	\delta=0)~\md E} \times N_\text{int}\nonumber\\
		&= \frac{\sum_j \Phi_j (\delta) }{\sum\limits_j \Phi_j (\delta=0)} \times
	N_\text{int},\quad\text{using eq.~\ref{eq:flux},}\label{eq:int_event_rate}
\end{align}
where $P(\delta)$ is the $\nu_\mu\rightarrow\nu_e$ appearance probability
for any $\delta_{CP}=\delta$, and $\Phi_j \equiv \Phi^{(e)}_\text{osc}(E_j)$.
Thus, substituting into equation~\ref{eq:event_rate_0},
\begin{align}
	N_i (\delta) &= \frac{N_\text{int}(\delta)}{\sum\limits_j \Phi_j (\delta)}
	\times \Phi_i (\delta)\nonumber\\
	&= \frac{N_\text{int}}{\sum\limits_j \Phi_j (\delta)} \frac{\sum_j \Phi_j
	(\delta)}{\sum\limits_j \Phi_j (\delta=0)} \times \Phi_j(\delta)\nonumber\\
	&= \frac{N_\text{int}}{\sum\limits_j \Phi_j (\delta=0)} \times
	\Phi_j(\delta).\label{eq:event_rate}
\end{align}
Equation~\ref{eq:event_rate} allows us to calculate an event rate spectrum
for any $\delta_{CP}$ using the integrated event rate from the CDR and two
predicted fluxes we calculate using eq.~\ref{eq:flux}.
Figure~\ref{fig:event_rate} shows examples of such spectra, for two values of
$\delta_{CP}$ and the two possible hierarchies.
\begin{figure}
	\centering
	\makebox[\textwidth][c]{
	\begin{subfigure}{0.6\textwidth}
	\includegraphics[width=\textwidth]{event_rate_0.pdf}
	\end{subfigure}
	\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{event_rate_pi.pdf}
	\end{subfigure}
	}
	\caption{Predicted event rate spectra at DUNE as a function of neutrino energy, for
	two values of $\delta_{CP}$ and the two hierarchies. For $\delta_{CP}=0$, the
	area under the curve (integrated event rate) is $N^\text{N}_\text{int}=861$ for the
	blue line and
	$N^\text{I}_\text{int}=495$ for the red line. For
	$\delta_{CP}=\pi/2$, the integrals are given by eq.~\ref{eq:int_event_rate}.}
\label{fig:event_rate}
\end{figure}

\subsection{Energy reconstruction}
In order to produce a more realistic model, we can introduce by hand
uncertainties on the energy reconstruction of neutrino events in the detector.
The method is very straightforward: for each event in each energy bin $i$, we
pick the reconstructed energy from a normal distribution around the true energy
$E_i$. The event is then reassigned to the bin corresponding to the
reconstructed energy.
\begin{figure}
	\centering
	\makebox[\textwidth][c]{
	\begin{subfigure}{0.6\textwidth}
	\includegraphics[width=\textwidth]{reconstructed_-.pdf}
	\end{subfigure}
	\begin{subfigure}{0.6\textwidth}
		\includegraphics[width=\textwidth]{reconstructed_+.pdf}
	\end{subfigure}
	}
	\caption{Predicted event rate spectra at DUNE after energy reconstruction.
	The statistical uncertainty on the energy of each event is picked to be
	$\sigma_E = \SI{0.5}{\GeV}$.}
\label{fig:event_rate_reconstructed}
\end{figure}

Figure~\ref{fig:event_rate_reconstructed} shows examples of reconstructed event
rate spectra for $\delta_{CP}=-\pi/2$ and $\delta_{CP}=\pi/2$. We observe that
this simplistic energy reconstruction flattens out the event distribution, but
also slightly shifts the oscillation maxima towards the high energies, hence
introducing a systematic error in the event rate.

\subsection{Sensitivity to the mass hierarchy and CP violation}
With our event rate spectra under NH, IH, and any $\delta_{CP}$, we can finally
estimate the sensitivity of DUNE using the methods of
section~\ref{sec:statistics}. 
\begin{figure}
	\centering
	\makebox[\textwidth][c]{
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{sens_mh_nh_rec.pdf}
\end{subfigure}
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{sens_mh_ih_rec.pdf}
\end{subfigure}}
\caption{Sensitivity of DUNE to the neutrino mass hierarchy as a
	function of $\delta_{CP}$ and the true hierarchy, for an exposure of
	150 kt$\cdot$MW$\cdot$year.}
	\label{fig:sens_mh}
\end{figure}

Figure~\ref{fig:sens_mh} shows the mass hierarchy sensitivity of DUNE as
defined in equation~\ref{eq:mean_dc2_mh_d}. It is useful now to recall the
interpretation of sensitivity for the mass hierarchy, as shown
in~\cite{blennow}: the square root of $\overline{\Delta\chi^2}$ corresponds to
the confidence level at which the experiment will be able to reject the false
hierarchy with a 50\% chance of type II error.

Qualitatively, we can see that if
the mass hierarchy is normally ordered, DUNE will more efficiently determine it
if $\delta_{CP}$ lies around $-\pi/2$. On the other hand, if it is inverted, a $\delta_{CP}$
around $\pi/2$ will be more favourable. Under an inverted hierarchy, the
average sensitivity is lower than for NH, which can be explained by the overall smaller
number of events expected to be observed under IH. 

However, for both
hierarchies, $\sqrt{|\overline{\Delta\chi^2}|}$ is greater than 5 for all
values of $\delta_{CP}$, hence we predict that \emph{DUNE will reject the false
hierarchy with a significance $>5\sigma$ whatever the true combination of parameters
turns out to be.}

\begin{figure}
	\centering
	\makebox[\textwidth][c]{
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{sens_cp_nh_rec.pdf}
\end{subfigure}
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{sens_cp_ih_rec.pdf}
\end{subfigure}}
\caption{Sensitivity of DUNE to CP violation through neutrino oscillations, as
	a function of the true value of $\delta_{CP}$, for an exposure of 150
	kt$\cdot$MW$\cdot$year.}
\label{fig:sens_cp}
\end{figure}

Figure~\ref{fig:sens_cp} shows the sensitivity of DUNE to CP violation, as
defined in eq.~\ref{eq:dc2_cpv}. Unfortunately, since we did not go through the effort of
determining the distribution of $\Delta\chi^2$ for CP violation, we are not in
a position to make as strong a statement as we did for sensitivity to the mass hierarchy.
However, we follow the conventions used in the literature and refer to
$\sqrt{\overline{\Delta\chi^2}}=3$ and $\sqrt{\overline{\Delta\chi^2}}=5$ as
the $3\sigma$ and $5\sigma$ significance on the discovery of CP violation,
respectively (see
for example~\cite{ballett, martin-albo, laguna-lbno, masud}). We predict a greater
significance on CP violation discovery if $\delta_{CP}$ lies in the upper half circle
$[0, \pi]$ for both mass hierarchies. The fraction of values of $\delta_{CP}$
for which the significance is greater than $5\sigma$ is relatively small,
indicating that a longer exposure or complementary results from a different
experiment are required to reduce the probability of error.
The DUNE experiment is expected not only to run in neutrino mode, where mainly
neutrinos are produced at the LBNF, but also in anti-neutrino mode. This
is expected to increase the sensitivity to CP violation by a significant amount
but was not taken into account in our model. In this sense, our estimate of
$\overline{\Delta\chi^2}$ is very conservative and should be regarded as so.


\section{Hyper-K sensitivity}\label{sec:hyperk}
In order to have a point of reference to compare DUNE to, we applied the
exact same procedure to a second future experiment. The Hyper-K detector
is the planned upgrade to the SuperK detector in Japan. Fortunately for us, the
Hyper-K design report\cite{hyperk} contains much the same information as the
DUNE CDR, allowing us to reach the same results with minimal changes to
the codebase. 

While Hyper-K is also sensitive to atmospheric neutrinos, our
model was originally designed for the purpose of modelling accelerator-based
neutrinos only. Hence we consider only those neutrino events which arise from the
J-PARC beam, without taking into account atmospheric events, or even
mis-identified beam events. The J-PARC accelerator is located \SI{295}{\km}
away from the Hyper-K detector, which is a much shorter baseline than the
LBNF-DUNE baseline of \SI{1300}{\km}.

In the design report, the performance of Hyper-K is estimated through models of
the beamline and Cherenkov detector. The expected number of $\nu_e$ appearance
events after a 10-year runtime, assuming NH and $\delta_{CP}=0$, is 2300.
As discussed in section~\ref{sec:event}, this is sufficient to extrapolate the
expected number of events under both hierarchies and any $\delta_{CP}$.
Note that the sensitivity plots we present for DUNE and Hyper-K should be
compared while keeping in mind that their respective exposures are not
necessarily equivalent. While we quote an absolute exposure of ten years for
Hyper-K, the quoted exposure 150 kt$\cdot$MW$\cdot$year for DUNE is relative to
the final beam power and the detector's final fiducial mass.

\begin{figure}
	\centering
	\makebox[\textwidth][c]{
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{hk_sens_mh_nh.pdf}
\end{subfigure}
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{hk_sens_mh_ih.pdf}
\end{subfigure}}
\caption{Sensitivity of Hyper-K to the mass hierarchy for an exposure to the J-PARC
	beam of 10 years, as a function of $\delta_{CP}$ and the mass hierarchy.}
\label{fig:hk_sens_mh}
\end{figure}

\begin{figure}
	\centering
	\makebox[\textwidth][c]{
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{hk_sens_cp_nh.pdf}
\end{subfigure}
\begin{subfigure}[b]{0.6\textwidth}
	\centering
	\includegraphics[width=\textwidth]{hk_sens_cp_ih.pdf}
\end{subfigure}}
\caption{Sensitivity of Hyper-K to CP violation for an exposure to the J-PARC
	beam of 10 years, as a function of $\delta_{CP}$ and the mass hierarchy.}
\label{fig:hk_sens_cp}
\end{figure}

We show the sensitivity of Hyper-K to the mass hierarchy and to CP violation in
figures~\ref{fig:hk_sens_mh} and~\ref{fig:hk_sens_cp}, respectively.
Although the total number of events we record for Hyper-K is almost three times
as many as for DUNE, the latter is overwhelmingly more sensitive to the mass
hierarchy. This is explained by the fact that at a baseline of \SI{295}{\km},
the effects of matter on the oscillations are small, and the dependence of the
oscillation probability on the mass hierarchy is therefore weak. 

The mass hierarchy determination significance, for Hyper-K, is smaller than
$3\sigma$ for all values of $\delta_{CP}$ if IH is true. It is smaller than
$5\sigma$ for all values of $\delta_{CP}$ if NH is true, and only greater than
$3\sigma$ for about 30\% of the possible $\delta_{CP}$ values.
Keep in mind that since we are not taking into account the atmospheric
neutrino events, we are only showing here a partial sensitivity. 
Furthermore, plans are being discussed\cite{t2hkk} to build a second Hyper-K detector in
the path of the J-PARC beam in Korea, at a baseline 1000-1300\si{\km}.
With a baseline similar to DUNE, this upgrade is expected to increase the mass
hierarchy sensitivity of Hyper-K to a $6\sigma$ significance even for the least
favourable $\delta_{CP}$ values.

On the other hand, we predict that \emph{Hyper-K will be extremely sensitive to CP
violation, ruling out CP conservation with a significance $>5\sigma$ for almost
every value of $\delta_{CP}$ different from $0$ and $\pi$.}

In the next and final chapter, we will summarize and interpret our results and
conclude by touching on the shortcomings of this project and the many ways in
which it could be expanded through future work.






